
#include <cmath>
#include <iostream>
#include <sstream>
#include <iomanip>
#include <string>
#include <memory>
#include <thread>
#include <atomic>

#include <NVX/nvx.h>
#include <NVX/nvx_timer.hpp>

#include <NVX/Application.hpp>
#include <NVX/ConfigParser.hpp>
#include <OVX/FrameSourceOVX.hpp>
#include <OVX/RenderOVX.hpp>
#include <NVX/SyncTimer.hpp>
#include <OVX/UtilityOVX.hpp>

#define NUM_SOURCES 4

// Process events
struct EventData
{
    EventData(): showSource(true), stop(false), pause(false), sourceVideoNumber(0) {}

    bool showSource;
    bool stop;
    bool pause;
    uint8_t sourceVideoNumber;
};


void keyboardEventCallback(void* eventData, vx_char key, vx_uint32 /*x*/, vx_uint32 /*y*/)
{
    EventData* data = static_cast<EventData*>(eventData);

    if (key == 27)  // escape
        data->stop = true;
    else if (key == 32) // space
        data->pause = !data->pause;
    else if (key == 'm')
    {
        data->showSource = !data->showSource;
        data->sourceVideoNumber = 1;
    }
    else if (key == '1')
        data->sourceVideoNumber = 1;
    else if (key == '2')
        data->sourceVideoNumber = 2;
    else if (key == '3')
        data->sourceVideoNumber = 3;
    else if (key == '4')
        data->sourceVideoNumber = 4;
}

// Add atomic flags for each frame source
std::vector<std::unique_ptr<ovxio::FrameSource>> frameSources(NUM_SOURCES);
std::vector<std::atomic<bool>> reopenFlags(NUM_SOURCES);

void reopenFrameSource(std::unique_ptr<ovxio::FrameSource>& frameSource, std::atomic<bool>& reopenFlag)
{
    while (reopenFlag){
        if (frameSource->open()){
            reopenFlag = false;  // Reset the flag when successful
            std::cout << "Frame source reopened successfully!" << std::endl;
        }
        else{
            std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Retry after a delay
        }
    }
}

void startReopenThread(std::unique_ptr<ovxio::FrameSource>& frameSource, std::atomic<bool>& reopenFlag){
    std::thread([&frameSource, &reopenFlag]() { reopenFrameSource(frameSource, reopenFlag); }).detach();
}

// main - Application entry point
int main(int argc, char** argv)
{
    try
    {
        nvxio::Application &app = nvxio::Application::get();
        ovxio::printVersionInfo();

        // Take video inputs

        std::string sourceUri[NUM_SOURCES] = {
            app.findSampleFilePath("cars.mp4"),
            app.findSampleFilePath("signs.avi"),
            app.findSampleFilePath("parking.avi"),
            app.findSampleFilePath("pedestrians.mp4")
        };

        // Take video inputs with full path 
        // std::string sourceUri[NUM_SOURCES] = {
        //     "/media/raj/HP/data/cars.mp4",
        //     "/media/raj/HP/data/signs.avi",
        //     "/media/raj/HP/data/signs.avi",
        //     "/media/raj/HP/data/cars.mp4"
        // };

        app.init(argc, argv);

        // NVXIO-based renderer object and frame source are instantiated
        // and attached to the OpenVX context object. NVXIO ContextGuard
        // object is used to automatically manage the OpenVX context
        // creation and destruction.
        ovxio::ContextGuard context;
        vxDirective(context, VX_DIRECTIVE_ENABLE_PERFORMANCE);

        // Messages generated by the OpenVX framework will be given
        // to ovxio::stdoutLogCallback
        vxRegisterLogCallback(context, &ovxio::stdoutLogCallback, vx_false_e);

        // Create a NVXIO-based frame source
        std::unique_ptr<ovxio::FrameSource> frameSources[NUM_SOURCES];
        for (size_t i = 0; i < NUM_SOURCES; ++i) {
            frameSources[i] = std::unique_ptr<ovxio::FrameSource> (ovxio::createDefaultFrameSource(context, sourceUri[i]));
            if (!frameSources[i] || !frameSources[i]->open()){
                std::cerr << "Error: Can't open source URI" << std::endl;
                return nvxio::Application::APP_EXIT_CODE_NO_RESOURCE;
            }
        }

        ovxio::FrameSource::Parameters frameConfigs[NUM_SOURCES];
        for (size_t i = 0; i < NUM_SOURCES; ++i) {
            frameConfigs[i] = frameSources[i]->getConfiguration();
        }
        
        vx_uint32 frameWidth = frameConfigs[0].frameWidth;
        vx_uint32 frameHeight = frameConfigs[0].frameHeight;

        // Create a NVXIO-based render
        std::unique_ptr<ovxio::Render> render(ovxio::createDefaultRender(context, "Quad Cam Demo", frameWidth * 2, frameHeight * 2));
        if (!render){
            std::cerr << "Error: Cannot create render!" << std::endl;
            return nvxio::Application::APP_EXIT_CODE_NO_RENDER;
        }

        // The application recieves the keyboard events via the
        // keyboardEventCallback() function registered via the renderer object
        EventData eventData;
        render->setOnKeyboardEventCallback(keyboardEventCallback, &eventData);

        // Create OpenVX objects
        vx_image combinedImage = vxCreateImage(context, 2 * frameWidth, 2 * frameHeight, VX_DF_IMAGE_RGBX);
        NVXIO_CHECK_REFERENCE(combinedImage);   
        
        // create rectangle
        vx_rectangle_t rects[NUM_SOURCES] = {
            {0, 0, frameWidth, frameHeight},
            {frameWidth, 0, frameWidth * 2, frameHeight},
            {0, frameHeight, frameWidth, frameHeight * 2},
            {frameWidth, frameHeight, frameWidth * 2, frameHeight * 2}
        };

        vx_image tempImages[NUM_SOURCES]; // Create temporary image for resized frame
        vx_image rois[NUM_SOURCES];
        for (size_t i = 0; i < NUM_SOURCES; ++i){
            tempImages[i] = vxCreateImage(context, frameConfigs[i].frameWidth, frameConfigs[i].frameHeight, VX_DF_IMAGE_RGBX);
            NVXIO_CHECK_REFERENCE(tempImages[i]);

            rois[i] = vxCreateImageFromROI(combinedImage, &rects[i]);
            NVXIO_CHECK_REFERENCE(rois[i]);
        }

        // Timer Setup
        std::unique_ptr<nvxio::SyncTimer> syncTimer = nvxio::createSyncTimer();
        syncTimer->arm(1.0 / app.getFPSLimit());

        double proc_ms = 0, total_ms = 0;
        nvx::Timer totalTimer;
        nvx::Timer procTimer;
        totalTimer.tic();

        while (!eventData.stop)
        {
            procTimer.tic();
            
            if (!eventData.pause) {
                for (size_t i = 0; i < 4; ++i) {

                    if (reopenFlags[i])
                        continue;

                    ovxio::FrameSource::FrameStatus fetchStatus = frameSources[i]->fetch(tempImages[i]);

                     // Resize the frame to the desired resolution
                    if (fetchStatus == ovxio::FrameSource::OK) {
                        vx_status status = vxuScaleImage(context, tempImages[i], rois[i], VX_INTERPOLATION_TYPE_BILINEAR);
                        if (status != VX_SUCCESS) {
                            std::cerr << "Error: Failed to resize frame from source " << i << std::endl;
                            continue;
                        }
                    }

                    if (fetchStatus == ovxio::FrameSource::CLOSED && !reopenFlags[i]){
                        // Restart the frame source if closed
                        reopenFlags[i] = true;
                        startReopenThread(frameSources[i], reopenFlags[i]);
                    }
                }
            }

            // time capture
            proc_ms = procTimer.toc();
            syncTimer->synchronize();
            total_ms = totalTimer.toc();
            totalTimer.tic();

            // Show original image or detected edges
            if (eventData.showSource)
                render->putImage(combinedImage);
            else if (eventData.sourceVideoNumber > 0 && eventData.sourceVideoNumber <= 4)
                    render->putImage(rois[eventData.sourceVideoNumber-1]);

            // Display information and performance metrics
            std::ostringstream msg;
            msg << std::fixed << std::setprecision(1);

            msg << "Resolution: " << frameWidth << 'x' << frameHeight << std::endl;
            msg << "Algorithm: " << proc_ms << " ms / " << 1000.0 / proc_ms << " FPS" << std::endl;
            msg << "Display: " << total_ms  << " ms / " << 1000.0 / total_ms << " FPS" << std::endl;

            msg << std::setprecision(6);
            msg.unsetf(std::ios_base::floatfield);
            msg << "LIMITED TO " << app.getFPSLimit() << " FPS FOR DISPLAY" << std::endl;
            msg << "M - switch multi/single view" << std::endl;
            msg << "1|2|3|4 - switch input source" << std::endl;
            msg << "Space - pause/resume" << std::endl;
            msg << "Esc - close the demo";

            ovxio::Render::TextBoxStyle textStyle = {
                {255u, 255u, 255u, 255u}, // color
                {0u,   0u,   0u,   127u}, // bgcolor
                {10u, 10u} // origin
            };

            render->putTextViewport(msg.str(), textStyle);

            // Flush all rendering commands
            if (!render->flush())
                eventData.stop = true;
        }

        // Release all objects
        vxReleaseImage(&combinedImage);
    }
    
    catch (const std::exception& e)
    {
        std::cerr << "Error: " << e.what() << std::endl;
        return nvxio::Application::APP_EXIT_CODE_ERROR;
    }

    return nvxio::Application::APP_EXIT_CODE_SUCCESS;
}

