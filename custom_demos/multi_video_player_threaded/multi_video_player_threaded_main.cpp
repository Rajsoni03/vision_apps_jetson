
#include <cmath>
#include <iostream>
#include <sstream>
#include <iomanip>
#include <string>
#include <memory>
#include <thread>
#include <atomic>

#include <NVX/nvx.h>
#include <NVX/nvx_timer.hpp>

#include <NVX/Application.hpp>
#include <NVX/ConfigParser.hpp>
#include <OVX/FrameSourceOVX.hpp>
#include <OVX/RenderOVX.hpp>
#include <NVX/SyncTimer.hpp>
#include <OVX/UtilityOVX.hpp>

#define NUM_SOURCES 16
#define NUM_ROW 4
#define NUM_COL 4

// Process events
struct EventData
{
    EventData(): showSource(true), stop(false), pause(false), sourceVideoNumber(0) {}

    bool showSource;
    bool stop;
    bool pause;
    uint8_t sourceVideoNumber;
};


void keyboardEventCallback(void* eventData, vx_char key, vx_uint32 /*x*/, vx_uint32 /*y*/)
{
    EventData* data = static_cast<EventData*>(eventData);

    if (key == 27)  // escape
        data->stop = true;
    else if (key == 32) // space
        data->pause = !data->pause;
}

// Add atomic flags for each frame source
std::vector<std::unique_ptr<ovxio::FrameSource>> frameSources(NUM_SOURCES);
std::vector<std::atomic<bool>> reopenFlags(NUM_SOURCES);

void reopenFrameSource(std::unique_ptr<ovxio::FrameSource>& frameSource, std::atomic<bool>& reopenFlag)
{
    while (reopenFlag){
        if (frameSource->open()){
            reopenFlag = false;  // Reset the flag when successful
            std::cout << "Frame source reopened successfully!" << std::endl;
        }
        else{
            std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Retry after a delay
        }
    }
}

void startReopenThread(std::unique_ptr<ovxio::FrameSource>& frameSource, std::atomic<bool>& reopenFlag){
    std::thread([&frameSource, &reopenFlag]() { reopenFrameSource(frameSource, reopenFlag); }).detach();
}

// main - Application entry point
int main(int argc, char** argv)
{
    try
    {
        nvxio::Application &app = nvxio::Application::get();
        ovxio::printVersionInfo();

        std::string input_file_names[NUM_SOURCES] = {
            "car_dashcam_1.mp4",
            "car_dashcam_2.mp4",
            "car_dashcam_3.mp4",
            "car_dashcam_4.mp4",
            "car_dashcam_5.mp4",
            "car_dashcam_6.mp4",
            "car_dashcam_7.mp4",
            "car_dashcam_8.mp4",
            "car_dashcam_9.mp4",
            "car_dashcam_10.mp4",
            "car_dashcam_11.mp4",
            "car_dashcam_12.mp4",
            "car_dashcam_13.mp4",
            "car_dashcam_14.mp4",
            "car_dashcam_15.mp4",
            "car_dashcam_16.mp4",
        };

        std::string sourceUri[NUM_SOURCES];

        // Take video inputs from relative path
        for (size_t i = 0; i < NUM_SOURCES; ++i) {
            sourceUri[i] = app.findSampleFilePath(input_file_names[i]);
        }
        // Take video inputs with full path 
        // for (size_t i = 0; i < NUM_SOURCES; ++i) {
        //     sourceUri[i] = "/media/raj/HP/data/" + input_file_names[i];
        //     std::cout << sourceUri[i] << std::endl;
        // }

        app.init(argc, argv);

        // NVXIO-based renderer object and frame source are instantiated
        // and attached to the OpenVX context object. NVXIO ContextGuard
        // object is used to automatically manage the OpenVX context
        // creation and destruction.
        ovxio::ContextGuard context;
        vxDirective(context, VX_DIRECTIVE_ENABLE_PERFORMANCE);

        // Messages generated by the OpenVX framework will be given
        // to ovxio::stdoutLogCallback
        vxRegisterLogCallback(context, &ovxio::stdoutLogCallback, vx_false_e);

        // Create a NVXIO-based frame source
        std::unique_ptr<ovxio::FrameSource> frameSources[NUM_SOURCES];
        for (size_t i = 0; i < NUM_SOURCES; ++i) {
            frameSources[i] = std::unique_ptr<ovxio::FrameSource> (ovxio::createDefaultFrameSource(context, sourceUri[i]));
            if (!frameSources[i] || !frameSources[i]->open()){
                std::cerr << "Error: Can't open source URI" << std::endl;
                return nvxio::Application::APP_EXIT_CODE_NO_RESOURCE;
            }
        }

        ovxio::FrameSource::Parameters frameConfigs[NUM_SOURCES];
        for (size_t i = 0; i < NUM_SOURCES; ++i) {
            frameConfigs[i] = frameSources[i]->getConfiguration();
        }
        
        vx_uint32 frameWidth = frameConfigs[0].frameWidth;
        vx_uint32 frameHeight = frameConfigs[0].frameHeight;

        // Create OpenVX objects
        vx_image combinedImage = vxCreateImage(context, NUM_ROW * frameWidth, NUM_COL * frameHeight, VX_DF_IMAGE_RGBX);
        NVXIO_CHECK_REFERENCE(combinedImage);   
        
        // create rectangle
        vx_rectangle_t rects[NUM_SOURCES];
        vx_int32 index = 0;
        for (vx_int32 i = 0; i < NUM_ROW; ++i) {
            for (vx_int32 j = 0; j < NUM_COL; ++j) {
                std::cout << index << " | Width : " << j * frameWidth << " || Height : " << i * frameHeight << std::endl;
                rects[index++] = {
                    j * frameWidth,
                    i * frameHeight,
                    (j * frameWidth) + frameWidth,
                    (i * frameHeight) + frameHeight
                };
            }
        }

        // Create a NVXIO-based render
        std::unique_ptr<ovxio::Render> render(ovxio::createDefaultRender(context, "Quad Cam Demo", frameWidth * NUM_ROW, frameHeight * NUM_COL));
        if (!render){
            std::cerr << "Error: Cannot create render!" << std::endl;
            return nvxio::Application::APP_EXIT_CODE_NO_RENDER;
        }

        // The application recieves the keyboard events via the
        // keyboardEventCallback() function registered via the renderer object
        EventData eventData;
        render->setOnKeyboardEventCallback(keyboardEventCallback, &eventData);

        vx_image tempImages[NUM_SOURCES]; // Create temporary image for resized frame
        vx_image rois[NUM_SOURCES];
        for (size_t i = 0; i < NUM_SOURCES; ++i){
            tempImages[i] = vxCreateImage(context, frameConfigs[i].frameWidth, frameConfigs[i].frameHeight, VX_DF_IMAGE_RGBX);
            NVXIO_CHECK_REFERENCE(tempImages[i]);

            rois[i] = vxCreateImageFromROI(combinedImage, &rects[i]);
            NVXIO_CHECK_REFERENCE(rois[i]);
        }

        // Timer Setup
        std::unique_ptr<nvxio::SyncTimer> syncTimer = nvxio::createSyncTimer();
        syncTimer->arm(1.0 / app.getFPSLimit());

        double proc_ms = 0, total_ms = 0;
        nvx::Timer totalTimer;
        nvx::Timer procTimer;
        totalTimer.tic();

        double algo_fps = 0;
        double display_fps = 0;

        double avg_algo_fps = 0;
        double avg_display_fps = 0;

        int avg_fps_interval = 30;

        ovxio::Render::TextBoxStyle textStyle = {
            {255u, 255u, 255u, 255u}, // color
            {0u,   0u,   0u,   127u}, // bgcolor
            {10u, 10u} // origin
        };

        ovxio::FrameSource::FrameStatus fetchStatus = ovxio::FrameSource::OK;

        vx_uint64 iteration = 0;

        while (!eventData.stop)
        {
            procTimer.tic();
            
            if (!eventData.pause) {
                for (size_t i = 0; i < NUM_SOURCES; ++i) {

                    if (reopenFlags[i])
                        continue;

                    // Resize the frame to the desired resolution
                    if (frameConfigs[i].frameWidth != frameWidth || frameConfigs[i].frameHeight != frameHeight){
                        fetchStatus = frameSources[i]->fetch(tempImages[i]);
                        
                        if (fetchStatus == ovxio::FrameSource::OK) {
                            vx_status status = vxuScaleImage(context, tempImages[i], rois[i], VX_INTERPOLATION_TYPE_BILINEAR);
                            if (status != VX_SUCCESS) {
                                std::cerr << "Error: Failed to resize frame from source " << i << std::endl;
                                continue;
                            }
                        }
                    }
                    else{
                        fetchStatus = frameSources[i]->fetch(rois[i]);
                    }

                    if (fetchStatus == ovxio::FrameSource::CLOSED && !reopenFlags[i]){
                        // Restart the frame source if closed
                        reopenFlags[i] = true;
                        startReopenThread(frameSources[i], reopenFlags[i]);
                    }
                }
            }

            // time capture
            proc_ms = procTimer.toc();
            syncTimer->synchronize();
            total_ms = totalTimer.toc();
            totalTimer.tic();

            // Show original image or detected edges
            if (eventData.showSource)
                render->putImage(combinedImage);
            else if (eventData.sourceVideoNumber > 0 && eventData.sourceVideoNumber <= 4)
                    render->putImage(rois[eventData.sourceVideoNumber-1]);

            // Display information and performance metrics
            std::ostringstream msg;
            msg << std::fixed << std::setprecision(1);

            if (iteration % avg_fps_interval == 0){
                avg_algo_fps = algo_fps / avg_fps_interval;
                algo_fps = 0;
                avg_display_fps = display_fps / avg_fps_interval;
                display_fps = 0;
            }
            iteration++;

            algo_fps += 1000.0 / proc_ms;
            display_fps += 1000.0 / total_ms;

            msg << "Resolution: " << frameWidth * NUM_ROW << 'x' << frameHeight * NUM_COL << std::endl;
            msg << "Algorithm: " << proc_ms << " ms / " << avg_algo_fps << " FPS" << std::endl;
            msg << "Display: " << total_ms  << " ms / " << avg_display_fps << " FPS" << std::endl;

            msg << std::setprecision(6);
            msg.unsetf(std::ios_base::floatfield);
            msg << "LIMITED TO " << app.getFPSLimit() << " FPS FOR DISPLAY" << std::endl;
            msg << "Space - pause/resume" << std::endl;
            msg << "Esc - close the demo";

            render->putTextViewport(msg.str(), textStyle);

            // Flush all rendering commands
            if (!render->flush())
                eventData.stop = true;
        }

        // Release all objects
        vxReleaseImage(&combinedImage);
    }
    
    catch (const std::exception& e)
    {
        std::cerr << "Error: " << e.what() << std::endl;
        return nvxio::Application::APP_EXIT_CODE_ERROR;
    }

    return nvxio::Application::APP_EXIT_CODE_SUCCESS;
}
